# LLM Configuration
# Options: "openai", "llama3_1", "llama3_2"
LLM_PROVIDER=openai
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-3.5-turbo

# Local Llama endpoints
LLAMA_3_1_ENDPOINT=http://127.0.0.1:5050/generate_llama
LLAMA_3_1_STREAM_ENDPOINT=http://127.0.0.1:5050/generate_stream
LLAMA_3_2_ENDPOINT=http://127.0.0.1:5050/generate_llama
LLAMA_3_2_STREAM_ENDPOINT=http://127.0.0.1:5050/generate_stream

# TTS Configuration
# Options: "elevenlabs", "local", "neurosync"
TTS_PROVIDER=elevenlabs
ELEVENLABS_API_KEY=your_elevenlabs_api_key_here
ELEVENLABS_VOICE_ID=your_elevenlabs_voice_id_here
ELEVENLABS_MODEL_ID=eleven_monolingual_v1

# Local TTS Configuration
LOCAL_TTS_URL=http://127.0.0.1:5000/tts
LOCAL_TTS_VOICE=default

# Neurosync TTS Configuration
NEUROSYNC_TTS_URL=http://127.0.0.1:5000/text_to_blendshapes
NEUROSYNC_BLENDSHAPES_URL=http://127.0.0.1:5000/audio_to_blendshapes 
NEUROSYNC_TTS_VOICE=default

# LLM Configuration
LLM_MODEL=mistralai/Mistral-7B-Instruct-v0.3
LLM_MAX_LENGTH=2048
LLM_TEMPERATURE=0.5
LLM_TOP_P=0.9
LLM_REPETITION_PENALTY=1.0

# Authentication
HF_TOKEN=

# Quantization Settings
QUANTIZATION=fp8
BNB_4BIT_QUANT_TYPE=fp8
BNB_4BIT_USE_DOUBLE_QUANT=false
BNB_4BIT_COMPUTE_DTYPE=bfloat16

# TTS Configuration
TTS_MODEL=facebook/mms-tts-eng  # HuggingFace-compatible TTS model
TTS_SPEED=1.0  # 1.0 is normal speed, lower for slower, higher for faster
TTS_SPEAKER_WAV=voices/default.wav  # Path to reference voice sample for cloning
TTS_LANGUAGE=en  # Language code (en, fr, de, es, etc.)
TTS_STREAM_CHUNK_SIZE=50  # Increased from 20 to process more frames in each streaming chunk

# Pipeline Configuration
CHUNK_WORD_THRESHOLD=8  # Increased from 3 to get more natural speech chunks
SHOW_REALTIME_METRICS=true  # Whether to show metrics in real-time
SAVE_AUDIO=true  # Whether to save the generated audio
AUDIO_OUTPUT_PATH=combined_output.wav

# Performance Optimization
USE_CUDA=true  # auto, true, or false - set to true for 16GB VRAM
OPTIMIZE_MEMORY=true  # Use memory optimization techniques
TRUST_REMOTE_CODE=true  # Required for Mistral models
LOW_CPU_MEM_USAGE=true  # Helps with memory management